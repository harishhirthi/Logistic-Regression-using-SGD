{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I2S-uFqwSvmg"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FUxLkBjISvmr"
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xexp5GYNSvmz",
    "outputId": "48e3356f-3756-4945-f6b7-f643b59063b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "54vJVc_KSvm9"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9pKAn1-ASvm_"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r97pFTgrSvnE"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jykLIXZNSvnJ",
    "outputId": "2e462e5f-1546-4edf-bcc8-e7a42f9057d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g0-M6oXASvnO"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sShoMeocSvnP"
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gm6wi8L2SvnU",
    "outputId": "dccc42b5-e1eb-4e2f-9fa2-07f405d4f761"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q4WFoxgASvnc",
    "outputId": "469de818-0a3e-42e8-bc19-ac6d088b9617"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
      "Total training time: 0.04 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
      "Total training time: 0.06 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
      "Total training time: 0.07 seconds.\n",
      "Convergence after 10 epochs took 0.07 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7WaVxhGpSvnj",
    "outputId": "1e67badc-96e7-4633-eb72-1d4c24aaa295"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
       "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
       "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
       " (1, 15),\n",
       " array([-0.8531383]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Su9e8fRLSvno"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gcz5_UqCSvnq"
   },
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UOBvEchCSvnr"
   },
   "source": [
    "## Implement Logistc Regression with L2 regularization Using SGD: without using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xbn61rrXSvnt"
   },
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "14bA5yR3Svnv"
   },
   "source": [
    "- Load the datasets(train and test) into the respective arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c7183hFBSvnv"
   },
   "source": [
    "- Initialize the weight_vector and intercept term randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdLeFU0USvnx"
   },
   "source": [
    "- Calculate the initlal log loss for the train and test data with the current weight and intercept and store it in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pEVtAlO1Svny"
   },
   "source": [
    "- for each epoch:\n",
    "    - for each batch of data points in train: (keep batch size=1)\n",
    "        - calculate the gradient of loss function w.r.t each weight in weight vector\n",
    "        - Calculate the gradient of the intercept <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)} ← (1 − \\frac{αλ}{N} )w^{(t)} + αx_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))$ <br>\n",
    "        $b^{(t+1)} ← (b^t +  α(y_n - σ((w^{(t)})^{T} x_n+b^{t}))$ \n",
    "        - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
    "        - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
    "        you can stop the training\n",
    "        - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2qmRH4UpSvny"
   },
   "source": [
    "- Plot the train and test loss i.e on x-axis the epoch number, and on y-axis the loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lbZf9p5gSvn1"
   },
   "source": [
    "- <strong>GOAL</strong>: compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fpz8X5DMSvn2"
   },
   "outputs": [],
   "source": [
    "w = np.zeros_like(X_train[0])\n",
    "b = 0\n",
    "eta0  = 0.0001\n",
    "alpha = 0.0001\n",
    "N = len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code to implement SGD as per the above instructions\n",
    "# please choose the number of iternations on your own\n",
    "import math\n",
    "class SGD:\n",
    "    \n",
    "    def __init__(self, x):\n",
    "        self.w = np.zeros_like(X_train[0])\n",
    "        self.b = 0\n",
    "     \n",
    "    def Sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-(np.dot(x, self.w.T) + self.b)))  \n",
    "    \n",
    "    #Gradient of Weight\n",
    "    def grad_w(self, x, y, lamda, N):\n",
    "        y_pred = self.Sigmoid(x)  \n",
    "        return (-x * (y - y_pred)) + ((lamda / N)  * self.w) \n",
    "    \n",
    "    #Gradient of Intercept\n",
    "    def grad_b(self, x, y):\n",
    "        y_pred = self.Sigmoid(x)\n",
    "        return (-y + y_pred)\n",
    "    \n",
    "    def loss(self, y, y_pred, lamda):\n",
    "        h1 = - y * np.log10(y_pred) \n",
    "        h2 = - (1 - y) * np.log10(1 - y_pred)\n",
    "        h3 = (1 / len(y)) * (lamda / 2) * np.sum(np.square(self.w))\n",
    "        #h = np.sum((y * np.log10(y_pred) + (1 - y) * np.log10(1 - y_pred)) + ((1 / len(y)) * (lamda / 2) * np.sum(np.square(self.w))))\n",
    "        h = np.sum(h1 + h2 + h3)\n",
    "        return h / len(y)\n",
    "\n",
    "    def fit(self, x, y, x_t, y_t, epochs = 1, alpha = 1, lamda = 1): \n",
    "        N = len(x)\n",
    "        loss = []\n",
    "        loss1 = []\n",
    "        #Calculation of Initial Loss\n",
    "        y_pred = self.Sigmoid(x)\n",
    "        ini = self.loss(y, y_pred, lamda)\n",
    "        print(\"Inital_train_loss = \", ini)\n",
    "        loss.append(ini)\n",
    "        \n",
    "        y_pred_test = self.Sigmoid(x_t)\n",
    "        ini1 = self.loss(y_t, y_pred_test, lamda)\n",
    "        print(\"Inital_test_loss = \", ini1)\n",
    "        loss1.append(ini)\n",
    "        \n",
    "        \n",
    "        for epoch in tqdm_notebook(range(epochs), total=epochs, unit=\"epoch\"):\n",
    "            for x1, y1 in zip(x, y):\n",
    "            #j = np.random.choice(N, replace = False)\n",
    "            # Updation of Weight and Intercept \n",
    "                self.w -= alpha * self.grad_w(x1, y1, lamda, N)\n",
    "                self.b -= alpha * self.grad_b(x1, y1)\n",
    "            \n",
    "            y_pred = self.Sigmoid(x)\n",
    "            train = self.loss(y, y_pred, lamda)   \n",
    "            loss.append(train)\n",
    "            \n",
    "            y_pred_test = self.Sigmoid(x_t)\n",
    "            test = self.loss(y_t, y_pred_test, lamda)\n",
    "            loss1.append(test)\n",
    "            \n",
    "            if(loss[-1] == loss[-2]):\n",
    "                break\n",
    "        \n",
    "            print(\"Epoch\", epoch, \"Train_loss\", train, \"Test_loss\", test)\n",
    "        \n",
    "        p = list(range(0,epochs+1))\n",
    "        print(\"Optimal_weigth_vector\", self.w)\n",
    "        print(\"Optimal_intercept\", self.b)\n",
    "        plt.plot(loss, label = 'Train_loss')\n",
    "        plt.plot(loss1, label = 'Test_loss')\n",
    "        plt.scatter(p, loss)\n",
    "        plt.scatter(p, loss1)\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Log_loss')\n",
    "        plt.grid(True)\n",
    "        plt.legend\n",
    "        plt.show()  \n",
    "            \n",
    "    \n",
    "    def pred(self, x):\n",
    "        predict = []\n",
    "        for x1 in x:\n",
    "            if self.Sigmoid(x1) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "                predict.append(1)\n",
    "            else:\n",
    "                predict.append(0)\n",
    "        return np.array(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital_train_loss =  0.3010299956639812\n",
      "Inital_test_loss =  0.3010299956639812\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12c53fa4e7be459f8b5f13ea6dfe09ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Train_loss 0.175469263007417 Test_loss 0.17596688093034574\n",
      "Epoch 1 Train_loss 0.16868174548072296 Test_loss 0.16940989946376206\n",
      "Epoch 2 Train_loss 0.16639953508321123 Test_loss 0.16721415690323105\n",
      "Epoch 3 Train_loss 0.16537405040172315 Test_loss 0.16622329884489517\n",
      "Epoch 4 Train_loss 0.16486122148174245 Test_loss 0.16572403978659642\n",
      "Epoch 5 Train_loss 0.16459114654172863 Test_loss 0.16545877263402292\n",
      "Epoch 6 Train_loss 0.1644448002489042 Test_loss 0.16531365673321544\n",
      "Epoch 7 Train_loss 0.16436411674725512 Test_loss 0.1652328402115104\n",
      "Epoch 8 Train_loss 0.16431912464311102 Test_loss 0.16518728324959892\n",
      "Epoch 9 Train_loss 0.1642938307002037 Test_loss 0.165161365793308\n",
      "\n",
      "Optimal_weigth_vector [-0.42315311  0.19095979 -0.14588118  0.33814991 -0.21196623  0.56525978\n",
      " -0.44538357 -0.09171679  0.21795314  0.16977398  0.19522044  0.00229554\n",
      " -0.07781461  0.33882618  0.02214234]\n",
      "Optimal_intercept -0.8500967712838059\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "sgd.fit(X_train, y_train, X_test, y_test, epochs = 10, alpha = eta0, lamda = alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95536\n",
      "0.95296\n"
     ]
    }
   ],
   "source": [
    "# Accuracy of Train and Test\n",
    "print(1-np.sum(y_train - sgd.pred(X_train))/len(X_train))\n",
    "print(1-np.sum(y_test  - sgd.pred(X_test))/len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yy8jWaa7Svn_",
    "outputId": "a5bdc6de-084e-4c0d-d905-3529d0dd268a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.0002138 ,  0.00548413,  0.00270918, -0.00329416, -0.00377953,\n",
       "          0.00509399,  0.00704126,  0.00237134,  0.00867994, -0.01106728,\n",
       "         -0.00183147, -0.00192361,  0.00178909,  0.00029817, -0.00052487]]),\n",
       " array([0.00304153]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
    "sgd.w-clf.coef_, sgd.b-clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "48gx6wQKSvoE",
    "outputId": "73838465-1f8e-4697-fe22-c49a816e1207"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95536\n",
      "0.95296\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(w, x, b):\n",
    "        return 1 / (1 + np.exp(-(np.dot(x, w.T) + b))) \n",
    "\n",
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        if sigmoid(w, X[i], b) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "    return np.array(predict)\n",
    "print(1-np.sum(y_train - pred(sgd.w,sgd.b,X_train))/len(X_train))\n",
    "print(1-np.sum(y_test  - pred(sgd.w,sgd.b,X_test))/len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Logistic Regression using SGD.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
